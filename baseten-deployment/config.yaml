build_commands:
  - apt-get update && apt-get install git git-lfs -y
  - git lfs install
  - git clone https://huggingface.co/hubertsiuzdak/snac_24khz /app/snac_24khz
environment_variables:
  ENABLE_EXECUTOR_API: "1"
model_metadata:
  example_model_input:
    max_tokens: 10000
    prompt:
      "In todays fast-paced world, finding balance between work and personal
      life is more important than ever. With the constant demands of technology, remote
      communication, "
    voice: tara
  tags:
    - force-legacy-api-non-openai-compatible
model_name: Salient-TTS
python_version: py39
requirements:
  - snac==1.2.1
  - torch==2.7.0
  - batched==0.1.4
  - httpx
  - websockets
  - pysbd
  - numpy
  - transformers
  - g2p-en
  - fastapi
  - starlette
resources:
  accelerator: H100_40GB
  cpu: "1"
  memory: 10Gi
  use_gpu: true
secrets:
  hf_access_token:
runtime:
  is_websocket_endpoint: true
  transport:
    kind: websocket
    ping_interval_seconds: null
    ping_timeout_seconds: null
trt_llm:
  build:
    base_model: llama
    checkpoint_repository:
      repo: TrySalient/tts-collections-test-verbalized
      revision: "main"
      source: HF
    max_batch_size: 256
    # set higher, so we can always use the max batch size in a single iter.
    max_num_tokens: 16384
    # 65536 would be around 600s of audio, typically model produces max 120s.
    max_seq_len: 65536
    num_builder_gpus: 1
    # quantization_config:
    #   # TODO: Generate a typical dataset (input + output tokens) in target language
    #   # or disable quantization for other languages
    #   calib_dataset: "cnn_dailymail"
    # plugin_configuration:
    #   use_fp8_context_fmha: false
    quantization_type: no_quant
    tensor_parallel_count: 1